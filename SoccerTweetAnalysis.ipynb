{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import and create a new SQLContext \n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the country CSV file into an RDD.\n",
    "country_lines = sc.textFile('file:///home/cloudera/Downloads/big-data-3/final-project/country-list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afghanistan, AFG\r",
      "\r\n",
      "Albania, ALB\r",
      "\r\n",
      "Algeria, ALG\r",
      "\r\n",
      "American Samoa, ASA\r",
      "\r\n",
      "Andorra, AND\r",
      "\r\n",
      "Angola, ANG\r",
      "\r\n",
      "Anguilla, AIA\r",
      "\r\n",
      "Antigua and Barbuda, ATG\r",
      "\r\n",
      "Argentina, ARG\r",
      "\r\n",
      "Armenia, ARM\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head country-list.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert each line into a pair of words\n",
    "words = country_lines.flatMap(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuples = country_lines.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert each pair of words into a tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='Afghanistan', code=' AFG'),\n",
       " Row(country='Albania', code=' ALB'),\n",
       " Row(country='Algeria', code=' ALG')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame, look at schema and contents\n",
    "countryDF = sqlContext.createDataFrame(tuples, [\"country\", \"code\"])\n",
    "countryDF.printSchema()\n",
    "countryDF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read tweets CSV file into RDD of lines\n",
    "export_csv = sc.textFile('file:///home/cloudera/Downloads/big-data-3/mongodb/export_twitter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13995"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_csv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean the data: some tweets are empty. Remove the empty tweets using filter() \n",
    "#tweets_text_clean=export_csv.filter(lambda x:len(x)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_text_clean=export_csv.filter(lambda x:len(x.strip())>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13385"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform WordCount on the cleaned tweet texts. (note: this is several lines.)\n",
    "tweets_words = tweets_text_clean.flatMap(lambda line : line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183304"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuples= tweets_words.map(lambda word:(word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_counts=tuples.reduceByKey(lambda a,b:(a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26634"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_counts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='', count=3280),\n",
       " Row(country='mobile', count=1),\n",
       " Row(country='#FridayNightTouchdown', count=1),\n",
       " Row(country='Just', count=44),\n",
       " Row(country='BONUSES,', count=1),\n",
       " Row(country='like?\"', count=1),\n",
       " Row(country='recieve', count=1),\n",
       " Row(country='Bellow', count=1),\n",
       " Row(country='now\"', count=1),\n",
       " Row(country='https://t.co/W4QluWGyeq', count=1)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame of tweet word counts\n",
    "tweets_countsDF=sqlContext.createDataFrame(tweets_counts, [\"country\", \"count\"])\n",
    "tweets_countsDF.printSchema()\n",
    "tweets_countsDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             country|count|\n",
      "+--------------------+-----+\n",
      "|                    | 3280|\n",
      "|              mobile|    1|\n",
      "|#FridayNightTouch...|    1|\n",
      "|                Just|   44|\n",
      "|            BONUSES,|    1|\n",
      "|              like?\"|    1|\n",
      "|             recieve|    1|\n",
      "|              Bellow|    1|\n",
      "|                now\"|    1|\n",
      "|https://t.co/W4Ql...|    1|\n",
      "|https://t.co/Jii7...|    1|\n",
      "|              review|    1|\n",
      "|                 Can|   37|\n",
      "|https://t.co/UBBj...|    1|\n",
      "|        @MattHDGamer|    1|\n",
      "|https://t.co/k1oj...|    1|\n",
      "|                ago\"|    1|\n",
      "|             GERMANY|    1|\n",
      "|       Revolutionary|    1|\n",
      "|https://t.co/1zml...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_countsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|country|count|\n",
      "+-------+-----+\n",
      "|GERMANY|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the country and tweet data frames (on the appropriate column)\n",
    "tweets_countsDF.filter(tweets_countsDF['country'] =='GERMANY').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merge = tweets_countsDF.join(countryDF, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.select(\"country\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|    country|count|\n",
      "+-----------+-----+\n",
      "|   Thailand|    1|\n",
      "|    Iceland|    1|\n",
      "|     Mexico|    1|\n",
      "|      Wales|    1|\n",
      "|    Denmark|    1|\n",
      "|      India|    1|\n",
      "|   Portugal|    1|\n",
      "|     Poland|    1|\n",
      "|     Norway|    1|\n",
      "|     Guinea|    1|\n",
      "|   Slovakia|    1|\n",
      "|     Canada|    1|\n",
      "|Netherlands|    1|\n",
      "|      Kenya|    1|\n",
      "|       Oman|    1|\n",
      "|      Qatar|    1|\n",
      "|     Brazil|    1|\n",
      "|    England|    1|\n",
      "|    Albania|    1|\n",
      "|  Argentina|    1|\n",
      "|   Scotland|    1|\n",
      "|      Ghana|    1|\n",
      "|       Iran|    1|\n",
      "|    Nigeria|    1|\n",
      "|       Iraq|    1|\n",
      "|    Georgia|    1|\n",
      "|     Kosovo|    1|\n",
      "|    Somalia|    1|\n",
      "|     Israel|    1|\n",
      "|     France|    1|\n",
      "|     Russia|    1|\n",
      "|      Sudan|    1|\n",
      "|    Germany|    1|\n",
      "|  Australia|    1|\n",
      "|      Spain|    1|\n",
      "|       Chad|    1|\n",
      "|      Japan|    1|\n",
      "|     Jordan|    1|\n",
      "|     Gambia|    1|\n",
      "|    Austria|    1|\n",
      "|Switzerland|    1|\n",
      "|      Italy|    1|\n",
      "|    Jamaica|    1|\n",
      "|      Nepal|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 1: number of distinct countries mentioned\n",
    "merge.groupBy('country').count().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|       397|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 2: number of countries mentioned in tweets.\n",
    "from pyspark.sql.functions import sum\n",
    "merge.select(sum('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/sql/dataframe.py:142: UserWarning: Use registerTempTable instead of registerAsTable.\n",
      "  warnings.warn(\"Use registerTempTable instead of registerAsTable.\")\n"
     ]
    }
   ],
   "source": [
    "merge.registerAsTable(\"merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = sqlContext.sql(\"select * from merge order by count desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+----+\n",
      "|    country|count|code|\n",
      "+-----------+-----+----+\n",
      "|     Norway|   52| NOR|\n",
      "|    Nigeria|   49| NGA|\n",
      "|     France|   42| FRA|\n",
      "|   Slovakia|   30| SVK|\n",
      "|    England|   25| ENG|\n",
      "|    Germany|   20| GER|\n",
      "|      Wales|   19| WAL|\n",
      "|     Russia|   15| RUS|\n",
      "|     Brazil|   13| BRA|\n",
      "|Netherlands|   13| NED|\n",
      "|     Canada|   11| CAN|\n",
      "|Switzerland|   10| SUI|\n",
      "|       Chad|    9| CHA|\n",
      "|     Guinea|    8| GUI|\n",
      "|      Spain|    8| ESP|\n",
      "|   Portugal|    8| POR|\n",
      "|       Iraq|    6| IRQ|\n",
      "|     Jordan|    6| JOR|\n",
      "|      Japan|    5| JPN|\n",
      "|    Austria|    5| AUT|\n",
      "+-----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = sqlContext.sql(\"select * from merge where country in ('Wales', 'Iceland', 'Japan')\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----+\n",
      "|country|count|code|\n",
      "+-------+-----+----+\n",
      "|Iceland|    2| ISL|\n",
      "|  Wales|   19| WAL|\n",
      "|  Japan|    5| JPN|\n",
      "+-------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'desc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-f9e8f18dce57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Table 1: top three countries and their counts.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtweets_countsDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m             raise AttributeError(\n\u001b[1;32m--> 842\u001b[1;33m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[0;32m    843\u001b[0m         \u001b[0mjc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'desc'"
     ]
    }
   ],
   "source": [
    "# Table 1: top three countries and their counts.\n",
    "from pyspark.sql.functions import desc\n",
    "tweets_countsDF.desc('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Table 2: counts for Wales, Iceland, and Japan.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
